utterance_id,start,end,duration,transcript,word_count,words,vad_segment_start,vad_segment_end,features,asr_confidence,speech_rate_wps,speech_rate_wpm,articulation_rate,pause_count,pause_rate,mean_pause_duration,std_pause_duration,total_pause_time,speaking_time_ratio,pitch_mean,pitch_std,pitch_range,pitch_variance,voiced_frames_ratio,rms_energy_mean,rms_energy_std,rms_energy_max,rms_energy_min,energy_dynamic_range,zero_crossing_rate,harmonic_noise_ratio,spectral_centroid_mean,spectral_centroid_std,mfcc_1_mean,mfcc_2_mean,mfcc_1_std,spectral_rolloff,spectral_bandwidth,snr_approximation,clipping_ratio
u001,0.26,0.48,0.22,Base,1,"[{'text': 'base', 'start': np.float64(0.26), 'end': np.float64(0.48), 'confidence': np.float64(0.6767)}]",0.03,0.99,"{'speech_rate_wpm': None, 'speech_rate_wps': None, 'articulation_rate': None, 'pause_count': None, 'pause_rate': None, 'mean_pause_duration': None, 'std_pause_duration': None, 'total_pause_time': None, 'speaking_time_ratio': None, 'pitch_mean': None, 'pitch_std': None, 'pitch_range': None, 'pitch_variance': None, 'voiced_frames_ratio': None, 'rms_energy_mean': None, 'rms_energy_std': None, 'rms_energy_max': None, 'rms_energy_min': None, 'energy_dynamic_range': None, 'zero_crossing_rate': None, 'harmonic_noise_ratio': None, 'spectral_centroid_mean': None, 'spectral_centroid_std': None, 'mfcc_1_mean': None, 'mfcc_2_mean': None, 'mfcc_1_std': None, 'spectral_rolloff': None, 'spectral_bandwidth': None, 'snr_approximation': None, 'clipping_ratio': None}",0.677,4.545,272.727,4.545,0,0.0,0.0,0.0,0.0,1.0,242.324,7.832,23.842,61.344,1.0,0.126,0.039,0.172,0.064,0.107,0.11,13.062,1987.079,659.652,-160.291,65.47,33.29,4197.545,1957.714,3.194,0.0
u002,1.86,11.84,9.98,Base variant straight off describes the problem of simultaneously minimizing two sources of error that prevents supervised learning algorithms from generalizing beyond their training,24,"[{'text': 'base', 'start': np.float64(1.86), 'end': np.float64(2.16), 'confidence': np.float64(0.9962)}, {'text': 'variant', 'start': np.float64(2.16), 'end': np.float64(2.5), 'confidence': np.float64(0.3813)}, {'text': 'straight', 'start': np.float64(2.5), 'end': np.float64(2.86), 'confidence': np.float64(0.7462)}, {'text': 'off', 'start': np.float64(2.86), 'end': np.float64(3.12), 'confidence': np.float64(0.5137)}, {'text': 'describes', 'start': np.float64(3.12), 'end': np.float64(3.48), 'confidence': np.float64(0.9082)}, {'text': 'the', 'start': np.float64(3.48), 'end': np.float64(3.82), 'confidence': np.float64(0.9956)}, {'text': 'problem', 'start': np.float64(3.82), 'end': np.float64(4.12), 'confidence': np.float64(0.9941)}, {'text': 'of', 'start': np.float64(4.12), 'end': np.float64(4.46), 'confidence': np.float64(0.9842)}, {'text': 'simultaneously', 'start': np.float64(4.46), 'end': np.float64(5.08), 'confidence': np.float64(0.8948)}, {'text': 'minimizing', 'start': np.float64(5.08), 'end': np.float64(5.9), 'confidence': np.float64(0.8538)}, {'text': 'two', 'start': np.float64(5.9), 'end': np.float64(6.54), 'confidence': np.float64(0.7633)}, {'text': 'sources', 'start': np.float64(6.54), 'end': np.float64(6.84), 'confidence': np.float64(0.9837)}, {'text': 'of', 'start': np.float64(6.84), 'end': np.float64(7.14), 'confidence': np.float64(0.9972)}, {'text': 'error', 'start': np.float64(7.14), 'end': np.float64(7.5), 'confidence': np.float64(0.9957)}, {'text': 'that', 'start': np.float64(7.5), 'end': np.float64(7.94), 'confidence': np.float64(0.8513)}, {'text': 'prevents', 'start': np.float64(7.94), 'end': np.float64(8.3), 'confidence': np.float64(0.8873)}, {'text': 'supervised', 'start': np.float64(8.3), 'end': np.float64(8.72), 'confidence': np.float64(0.0878)}, {'text': 'learning', 'start': np.float64(8.72), 'end': np.float64(9.14), 'confidence': np.float64(0.9921)}, {'text': 'algorithms', 'start': np.float64(9.14), 'end': np.float64(9.6), 'confidence': np.float64(0.9723)}, {'text': 'from', 'start': np.float64(9.6), 'end': np.float64(10.1), 'confidence': np.float64(0.9956)}, {'text': 'generalizing', 'start': np.float64(10.1), 'end': np.float64(10.82), 'confidence': np.float64(0.9845)}, {'text': 'beyond', 'start': np.float64(10.82), 'end': np.float64(11.28), 'confidence': np.float64(0.9512)}, {'text': 'their', 'start': np.float64(11.28), 'end': np.float64(11.58), 'confidence': np.float64(0.5551)}, {'text': 'training', 'start': np.float64(11.58), 'end': np.float64(11.84), 'confidence': np.float64(0.9264)}]",1.56,12.33,"{'speech_rate_wpm': None, 'speech_rate_wps': None, 'articulation_rate': None, 'pause_count': None, 'pause_rate': None, 'mean_pause_duration': None, 'std_pause_duration': None, 'total_pause_time': None, 'speaking_time_ratio': None, 'pitch_mean': None, 'pitch_std': None, 'pitch_range': None, 'pitch_variance': None, 'voiced_frames_ratio': None, 'rms_energy_mean': None, 'rms_energy_std': None, 'rms_energy_max': None, 'rms_energy_min': None, 'energy_dynamic_range': None, 'zero_crossing_rate': None, 'harmonic_noise_ratio': None, 'spectral_centroid_mean': None, 'spectral_centroid_std': None, 'mfcc_1_mean': None, 'mfcc_2_mean': None, 'mfcc_1_std': None, 'spectral_rolloff': None, 'spectral_bandwidth': None, 'snr_approximation': None, 'clipping_ratio': None}",0.842,2.405,144.289,2.405,0,0.0,0.0,0.0,0.0,1.0,205.535,25.105,129.009,630.243,0.913,0.07,0.038,0.249,0.001,0.248,0.113,2.582,1552.36,975.908,-271.599,97.892,74.506,2975.786,1512.447,1.841,0.0
u003,13.28,27.66,14.38,"By us error from overlays, simplistic assumptions in the model, variants error from the excesses, instability to small fluctuations in the training set. The rate of is that you can't minimize both at the same time.",47,"[{'text': 'By', 'start': np.float64(13.28), 'end': np.float64(13.32), 'confidence': np.float64(0.8627)}, {'text': 'us', 'start': np.float64(13.32), 'end': np.float64(13.64), 'confidence': np.float64(0.7346)}, {'text': 'error', 'start': np.float64(13.64), 'end': np.float64(13.9), 'confidence': np.float64(0.5155)}, {'text': 'from', 'start': np.float64(13.9), 'end': np.float64(14.18), 'confidence': np.float64(0.9662)}, {'text': 'overlays,', 'start': np.float64(14.18), 'end': np.float64(14.5), 'confidence': np.float64(0.5517)}, {'text': 'simplistic', 'start': np.float64(14.68), 'end': np.float64(14.9), 'confidence': np.float64(0.1594)}, {'text': 'assumptions', 'start': np.float64(14.9), 'end': np.float64(15.3), 'confidence': np.float64(0.9322)}, {'text': 'in', 'start': np.float64(15.3), 'end': np.float64(15.6), 'confidence': np.float64(0.9905)}, {'text': 'the', 'start': np.float64(15.6), 'end': np.float64(15.7), 'confidence': np.float64(0.9957)}, {'text': 'model,', 'start': np.float64(15.7), 'end': np.float64(16.08), 'confidence': np.float64(0.9942)}, {'text': 'variants', 'start': np.float64(16.44), 'end': np.float64(16.78), 'confidence': np.float64(0.847)}, {'text': 'error', 'start': np.float64(16.78), 'end': np.float64(17.16), 'confidence': np.float64(0.7898)}, {'text': 'from', 'start': np.float64(17.16), 'end': np.float64(17.42), 'confidence': np.float64(0.9898)}, {'text': 'the', 'start': np.float64(17.42), 'end': np.float64(17.62), 'confidence': np.float64(0.9952)}, {'text': 'excesses,', 'start': np.float64(17.62), 'end': np.float64(18.12), 'confidence': np.float64(0.5978)}, {'text': 'instability', 'start': np.float64(18.22), 'end': np.float64(18.42), 'confidence': np.float64(0.3199)}, {'text': 'to', 'start': np.float64(18.42), 'end': np.float64(18.84), 'confidence': np.float64(0.9726)}, {'text': 'small', 'start': np.float64(18.84), 'end': np.float64(19.14), 'confidence': np.float64(0.9223)}, {'text': 'fluctuations', 'start': np.float64(19.14), 'end': np.float64(19.54), 'confidence': np.float64(0.9741)}, {'text': 'in', 'start': np.float64(19.54), 'end': np.float64(19.98), 'confidence': np.float64(0.9986)}, {'text': 'the', 'start': np.float64(19.98), 'end': np.float64(20.02), 'confidence': np.float64(0.9831)}, {'text': 'training', 'start': np.float64(20.02), 'end': np.float64(20.26), 'confidence': np.float64(0.9842)}, {'text': 'set.', 'start': np.float64(20.26), 'end': np.float64(20.68), 'confidence': np.float64(0.9103)}, {'text': 'The', 'start': np.float64(21.22), 'end': np.float64(21.24), 'confidence': np.float64(0.9554)}, {'text': 'rate', 'start': np.float64(21.24), 'end': np.float64(21.44), 'confidence': np.float64(0.2863)}, {'text': 'of', 'start': np.float64(21.44), 'end': np.float64(21.66), 'confidence': np.float64(0.9522)}, {'text': 'is', 'start': np.float64(21.66), 'end': np.float64(21.84), 'confidence': np.float64(0.6249)}, {'text': 'that', 'start': np.float64(21.84), 'end': np.float64(22.0), 'confidence': np.float64(0.9921)}, {'text': 'you', 'start': np.float64(22.0), 'end': np.float64(22.12), 'confidence': np.float64(0.8994)}, {'text': ""can't"", 'start': np.float64(22.12), 'end': np.float64(22.64), 'confidence': np.float64(0.8875)}, {'text': 'minimize', 'start': np.float64(22.64), 'end': np.float64(22.7), 'confidence': np.float64(0.8434)}, {'text': 'both', 'start': np.float64(22.7), 'end': np.float64(23.08), 'confidence': np.float64(0.9989)}, {'text': 'at', 'start': np.float64(23.08), 'end': np.float64(23.32), 'confidence': np.float64(0.9689)}, {'text': 'the', 'start': np.float64(23.32), 'end': np.float64(23.4), 'confidence': np.float64(0.9598)}, {'text': 'same', 'start': np.float64(23.4), 'end': np.float64(23.6), 'confidence': np.float64(0.9998)}, {'text': 'time.', 'start': np.float64(23.6), 'end': np.float64(24.02), 'confidence': np.float64(0.998)}, {'text': 'As', 'start': np.float64(24.22), 'end': np.float64(24.4), 'confidence': np.float64(0.9834)}, {'text': 'you', 'start': np.float64(24.4), 'end': np.float64(24.5), 'confidence': np.float64(0.9179)}, {'text': 'try', 'start': np.float64(24.5), 'end': np.float64(24.7), 'confidence': np.float64(0.8214)}, {'text': 'to', 'start': np.float64(24.7), 'end': np.float64(24.88), 'confidence': np.float64(0.9986)}, {'text': 'reduce', 'start': np.float64(24.88), 'end': np.float64(25.16), 'confidence': np.float64(0.9523)}, {'text': 'one,', 'start': np.float64(25.16), 'end': np.float64(25.46), 'confidence': np.float64(0.7076)}, {'text': 'the', 'start': np.float64(25.5), 'end': np.float64(25.66), 'confidence': np.float64(0.9322)}, {'text': 'other', 'start': np.float64(25.66), 'end': np.float64(25.68), 'confidence': np.float64(0.9543)}, {'text': 'is', 'start': np.float64(25.68), 'end': np.float64(25.96), 'confidence': np.float64(0.9839)}, {'text': 'inevitably', 'start': np.float64(25.96), 'end': np.float64(27.18), 'confidence': np.float64(0.7121)}, {'text': 'increased.', 'start': np.float64(27.18), 'end': np.float64(27.66), 'confidence': np.float64(0.5357)}]",13.08,27.66,"{'speech_rate_wpm': None, 'speech_rate_wps': None, 'articulation_rate': None, 'pause_count': None, 'pause_rate': None, 'mean_pause_duration': None, 'std_pause_duration': None, 'total_pause_time': None, 'speaking_time_ratio': None, 'pitch_mean': None, 'pitch_std': None, 'pitch_range': None, 'pitch_variance': None, 'voiced_frames_ratio': None, 'rms_energy_mean': None, 'rms_energy_std': None, 'rms_energy_max': None, 'rms_energy_min': None, 'energy_dynamic_range': None, 'zero_crossing_rate': None, 'harmonic_noise_ratio': None, 'spectral_centroid_mean': None, 'spectral_centroid_std': None, 'mfcc_1_mean': None, 'mfcc_2_mean': None, 'mfcc_1_std': None, 'spectral_rolloff': None, 'spectral_bandwidth': None, 'snr_approximation': None, 'clipping_ratio': None}",0.848,3.268,196.106,3.268,4,0.087,0.32,0.145,1.28,0.911,208.203,31.333,211.356,981.774,0.836,0.06,0.034,0.153,0.001,0.153,0.124,1.198,1715.36,1094.476,-288.629,96.615,85.593,3248.368,1550.863,1.756,0.0
